{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e6e8ac",
   "metadata": {
    "papermill": {
     "duration": 0.030634,
     "end_time": "2025-05-29T14:35:58.183385",
     "exception": false,
     "start_time": "2025-05-29T14:35:58.152751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*The data, concept, and initial implementation of this notebook was done in Colab by Ross Wightman, the creator of timm. I (Jeremy Howard) did some refactoring, curating, and expanding of the analysis, and added prose.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f4501",
   "metadata": {
    "papermill": {
     "duration": 0.027786,
     "end_time": "2025-05-29T14:35:58.240603",
     "exception": false,
     "start_time": "2025-05-29T14:35:58.212817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "通过一个图表来直观看出各个图像识别模型的优劣"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278071fd",
   "metadata": {
    "papermill": {
     "duration": 0.028239,
     "end_time": "2025-05-29T14:35:58.297968",
     "exception": false,
     "start_time": "2025-05-29T14:35:58.269729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## timm\n",
    "\n",
    "[PyTorch Image Models](https://timm.fast.ai/) (timm) is a wonderful library by Ross Wightman which provides state-of-the-art pre-trained computer vision models. It's like Huggingface Transformers, but for computer vision instead of NLP (and it's not restricted to transformers-based models)!\n",
    "\n",
    "Ross has been kind enough to help me understand how to best take advantage of this library by identifying the top models. I'm going to share here so of what I've learned from him, plus some additional ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f1ba2",
   "metadata": {
    "papermill": {
     "duration": 0.02834,
     "end_time": "2025-05-29T14:35:58.353586",
     "exception": false,
     "start_time": "2025-05-29T14:35:58.325246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The data\n",
    "\n",
    "Ross regularly benchmarks new models as they are added to timm, and puts the results in a CSV in the project's GitHub repo. To analyse the data, we'll first clone the repo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e40beb",
   "metadata": {
    "papermill": {
     "duration": 0.028708,
     "end_time": "2025-05-29T14:35:58.412323",
     "exception": false,
     "start_time": "2025-05-29T14:35:58.383615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ross将每个模型的性能放在了一个CSV文件中, 为了分析这个数据需要先获取这个项目的仓库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511fca8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:35:58.471611Z",
     "iopub.status.busy": "2025-05-29T14:35:58.470843Z",
     "iopub.status.idle": "2025-05-29T14:36:01.529670Z",
     "shell.execute_reply": "2025-05-29T14:36:01.528245Z"
    },
    "papermill": {
     "duration": 3.09285,
     "end_time": "2025-05-29T14:36:01.532793",
     "exception": false,
     "start_time": "2025-05-29T14:35:58.439943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-image-models'...\r\n",
      "remote: Enumerating objects: 454, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (454/454), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (391/391), done.\u001b[K\r\n",
      "remote: Total 454 (delta 98), reused 239 (delta 59), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (454/454), 2.84 MiB | 16.34 MiB/s, done.\r\n",
      "Resolving deltas: 100% (98/98), done.\r\n",
      "/kaggle/working/pytorch-image-models/results\n"
     ]
    }
   ],
   "source": [
    "! git clone --depth 1 https://github.com/rwightman/pytorch-image-models.git\n",
    "%cd pytorch-image-models/results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dbd67a",
   "metadata": {
    "papermill": {
     "duration": 0.031767,
     "end_time": "2025-05-29T14:36:01.599782",
     "exception": false,
     "start_time": "2025-05-29T14:36:01.568015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using Pandas, we can read the two CSV files we need, and merge them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6de2e5",
   "metadata": {
    "papermill": {
     "duration": 0.033943,
     "end_time": "2025-05-29T14:36:01.666884",
     "exception": false,
     "start_time": "2025-05-29T14:36:01.632941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "用Pandas来解析CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab61d3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:36:01.734734Z",
     "iopub.status.busy": "2025-05-29T14:36:01.734417Z",
     "iopub.status.idle": "2025-05-29T14:36:01.753513Z",
     "shell.execute_reply": "2025-05-29T14:36:01.752385Z"
    },
    "papermill": {
     "duration": 0.055312,
     "end_time": "2025-05-29T14:36:01.755970",
     "exception": false,
     "start_time": "2025-05-29T14:36:01.700658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.read_csv('results-imagenet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee96fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:36:01.824093Z",
     "iopub.status.busy": "2025-05-29T14:36:01.823780Z",
     "iopub.status.idle": "2025-05-29T14:36:01.844831Z",
     "shell.execute_reply": "2025-05-29T14:36:01.843583Z"
    },
    "papermill": {
     "duration": 0.057563,
     "end_time": "2025-05-29T14:36:01.847199",
     "exception": false,
     "start_time": "2025-05-29T14:36:01.789636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_results['model_org'] = df_results['model'] \n",
    "df_results['model'] = df_results['model'].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b3284",
   "metadata": {
    "papermill": {
     "duration": 0.029905,
     "end_time": "2025-05-29T14:36:01.910378",
     "exception": false,
     "start_time": "2025-05-29T14:36:01.880473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll also add a \"family\" column that will allow us to group architectures into categories with similar characteristics:\n",
    "\n",
    "Ross has told me which models he's found the most usable in practice, so I'll limit the charts to just look at these. (I also include VGG, not because it's good, but as a comparison to show how far things have come in the last few years.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31c57a",
   "metadata": {
    "papermill": {
     "duration": 0.031937,
     "end_time": "2025-05-29T14:36:01.974808",
     "exception": false,
     "start_time": "2025-05-29T14:36:01.942871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "有着相同特征的模型被划入一个家族"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9115bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:36:02.041741Z",
     "iopub.status.busy": "2025-05-29T14:36:02.041441Z",
     "iopub.status.idle": "2025-05-29T14:36:02.050323Z",
     "shell.execute_reply": "2025-05-29T14:36:02.048863Z"
    },
    "papermill": {
     "duration": 0.048761,
     "end_time": "2025-05-29T14:36:02.055057",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.006296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(part, col):\n",
    "    df = pd.read_csv(f'/kaggle/working/pytorch-image-models/results/benchmark-{part}-amp-nhwc-pt113-cu117-rtx3090.csv').merge(df_results, on='model')\n",
    "    df['secs'] = 1. / df[col]\n",
    "    df['family'] = df.model.str.extract('^([a-z]+?(?:v2)?)(?:\\d|_|$)')\n",
    "    df = df[~df.model.str.endswith('gn')]\n",
    "    df.loc[df.model.str.contains('in22'),'family'] = df.loc[df.model.str.contains('in22'),'family'] + '_in22'\n",
    "    df.loc[df.model.str.contains('resnet.*d'),'family'] = df.loc[df.model.str.contains('resnet.*d'),'family'] + 'd'\n",
    "    return df[df.family.str.contains('^re[sg]netd?|beit|convnext|levit|efficient|vit|vgg|swin')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a558e08",
   "metadata": {
    "papermill": {
     "duration": 0.03455,
     "end_time": "2025-05-29T14:36:02.123224",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.088674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "原来的csv文件已更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a730a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:36:02.188065Z",
     "iopub.status.busy": "2025-05-29T14:36:02.187794Z",
     "iopub.status.idle": "2025-05-29T14:36:02.230330Z",
     "shell.execute_reply": "2025-05-29T14:36:02.229290Z"
    },
    "papermill": {
     "duration": 0.077418,
     "end_time": "2025-05-29T14:36:02.232770",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.155352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = get_data('infer', 'infer_samples_per_sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd21e7",
   "metadata": {
    "papermill": {
     "duration": 0.032511,
     "end_time": "2025-05-29T14:36:02.295993",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.263482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "列表的名称也发生更改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf28ea3",
   "metadata": {
    "papermill": {
     "duration": 0.031791,
     "end_time": "2025-05-29T14:36:02.358611",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.326820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3707f",
   "metadata": {
    "papermill": {
     "duration": 0.031761,
     "end_time": "2025-05-29T14:36:02.423518",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.391757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's the results for inference performance (see the last section for training performance). In this chart:\n",
    "\n",
    "- the x axis shows how many seconds it takes to process one image (**note**: it's a log scale)\n",
    "- the y axis is the accuracy on Imagenet\n",
    "- the size of each bubble is proportional to the size of images used in testing\n",
    "- the color shows what \"family\" the architecture is from.\n",
    "\n",
    "Hover your mouse over a marker to see details about the model. Double-click in the legend to display just one family. Single-click in the legend to show or hide a family.\n",
    "\n",
    "**Note**: on my screen, Kaggle cuts off the family selector and some plotly functionality -- to see the whole thing, collapse the table of contents on the right by clicking the little arrow to the right of \"*Contents*\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd85e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:36:02.487627Z",
     "iopub.status.busy": "2025-05-29T14:36:02.487337Z",
     "iopub.status.idle": "2025-05-29T14:37:07.916443Z",
     "shell.execute_reply": "2025-05-29T14:37:07.915019Z"
    },
    "papermill": {
     "duration": 65.463024,
     "end_time": "2025-05-29T14:37:07.918971",
     "exception": false,
     "start_time": "2025-05-29T14:36:02.455947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly==5.10.0\r\n",
      "  Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly==5.10.0) (8.0.1)\r\n",
      "Installing collected packages: plotly\r\n",
      "  Attempting uninstall: plotly\r\n",
      "    Found existing installation: plotly 5.7.0\r\n",
      "    Uninstalling plotly-5.7.0:\r\n",
      "      Successfully uninstalled plotly-5.7.0\r\n",
      "Successfully installed plotly-5.10.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install plotly==5.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f1d34b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:37:07.991340Z",
     "iopub.status.busy": "2025-05-29T14:37:07.990291Z",
     "iopub.status.idle": "2025-05-29T14:37:08.006154Z",
     "shell.execute_reply": "2025-05-29T14:37:08.005192Z"
    },
    "papermill": {
     "duration": 0.053733,
     "end_time": "2025-05-29T14:37:08.008660",
     "exception": false,
     "start_time": "2025-05-29T14:37:07.954927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "w,h = 1000,800\n",
    "\n",
    "def show_all(df, title, size):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # 按模型族分组添加散点\n",
    "    for family in df['family'].unique():\n",
    "        family_df = df[df['family'] == family]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=family_df['secs'],\n",
    "            y=family_df['top1'],\n",
    "            mode='markers',\n",
    "            name=family,\n",
    "            marker=dict(\n",
    "                size=family_df[size] ** 2,\n",
    "                sizemode='area',\n",
    "                sizeref=0.1 * max(family_df[size]) / (100**2)\n",
    "            ),\n",
    "            text=family_df['model_org'],\n",
    "            hoverinfo='text+x+y',\n",
    "            hovertemplate='<b>%{text}</b><br>Secs: %{x:.4f}<br>Top1: %{y:.2f}<br>Size: %{marker.size:.0f}<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    # 手动设置对数坐标轴\n",
    "    fig.update_xaxes(type='log', title='Seconds per Sample (log scale)')\n",
    "    fig.update_yaxes(title='Top-1 Accuracy')\n",
    "    \n",
    "    # 设置布局属性\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        width=w,\n",
    "        height=h,\n",
    "        template='plotly_white',\n",
    "        hovermode='closest',\n",
    "        xaxis=dict(automargin=\"left\")  # 使用字典形式设置automargin\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e6fd14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:37:08.086285Z",
     "iopub.status.busy": "2025-05-29T14:37:08.085955Z",
     "iopub.status.idle": "2025-05-29T14:37:08.243306Z",
     "shell.execute_reply": "2025-05-29T14:37:08.242230Z"
    },
    "papermill": {
     "duration": 0.20024,
     "end_time": "2025-05-29T14:37:08.245750",
     "exception": false,
     "start_time": "2025-05-29T14:37:08.045510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"kaggle\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cabac3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:37:08.318245Z",
     "iopub.status.busy": "2025-05-29T14:37:08.317927Z",
     "iopub.status.idle": "2025-05-29T14:37:08.615462Z",
     "shell.execute_reply": "2025-05-29T14:37:08.614225Z"
    },
    "papermill": {
     "duration": 0.336249,
     "end_time": "2025-05-29T14:37:08.618331",
     "exception": false,
     "start_time": "2025-05-29T14:37:08.282082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = show_all(df, 'Inference', 'infer_img_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b74211",
   "metadata": {
    "papermill": {
     "duration": 0.034338,
     "end_time": "2025-05-29T14:37:08.690069",
     "exception": false,
     "start_time": "2025-05-29T14:37:08.655731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That number of families can be a bit overwhelming, so I'll just pick a subset which represents a single key model from each of the families that are looking best in our plot. I've also separated convnext models into those which have been pretrained on the larger 22,000 category imagenet sample (`convnext_in22`) vs those that haven't (`convnext`). (Note that many of the best performing models were trained on the larger sample -- see the papers for details before coming to conclusions about the effectiveness of these architectures more generally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2b7fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:37:08.766418Z",
     "iopub.status.busy": "2025-05-29T14:37:08.765969Z",
     "iopub.status.idle": "2025-05-29T14:37:08.771771Z",
     "shell.execute_reply": "2025-05-29T14:37:08.770723Z"
    },
    "papermill": {
     "duration": 0.049442,
     "end_time": "2025-05-29T14:37:08.774233",
     "exception": false,
     "start_time": "2025-05-29T14:37:08.724791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subs = 'levit|resnetd?|regnetx|vgg|convnext.*|efficientnetv2|beit|swin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654cde1",
   "metadata": {
    "papermill": {
     "duration": 0.035116,
     "end_time": "2025-05-29T14:37:08.845389",
     "exception": false,
     "start_time": "2025-05-29T14:37:08.810273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this chart, I'll add lines through the points of each family, to help see how they compare -- but note that we can see that a linear fit isn't actually ideal here! It's just there to help visually see the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6b46be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:37:08.917771Z",
     "iopub.status.busy": "2025-05-29T14:37:08.917424Z",
     "iopub.status.idle": "2025-05-29T14:37:08.924316Z",
     "shell.execute_reply": "2025-05-29T14:37:08.922880Z"
    },
    "papermill": {
     "duration": 0.047011,
     "end_time": "2025-05-29T14:37:08.926837",
     "exception": false,
     "start_time": "2025-05-29T14:37:08.879826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_subs(df, title, size):\n",
    "    df_subs = df[df.family.str.fullmatch(subs)]\n",
    "    return px.scatter(df_subs, width=w, height=h, size=df_subs[size]**2, title=title,\n",
    "        trendline=\"ols\", trendline_options={'log_x':True},\n",
    "        x='secs',  y='top1', log_x=True, color='family', hover_name='model_org', hover_data=[size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5aee7e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:37:08.996787Z",
     "iopub.status.busy": "2025-05-29T14:37:08.996498Z",
     "iopub.status.idle": "2025-05-29T14:37:09.137392Z",
     "shell.execute_reply": "2025-05-29T14:37:09.135534Z"
    },
    "papermill": {
     "duration": 0.179453,
     "end_time": "2025-05-29T14:37:09.140119",
     "exception": true,
     "start_time": "2025-05-29T14:37:08.960666",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/210619079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_subs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Inference'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'infer_img_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_19/3081936654.py\u001b[0m in \u001b[0;36mshow_subs\u001b[0;34m(df, title, size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_subs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf_subs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     return px.scatter(df_subs, width=w, height=h, size=df_subs[size]**2, title=title,\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtrendline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ols\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrendline_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'log_x'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         x='secs',  y='top1', log_x=True, color='family', hover_name='model_org', hover_data=[size])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "show_subs(df, 'Inference', 'infer_img_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa863ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "From this, we can see that the *levit* family models are extremely fast for image recognition, and clearly the most accurate amongst the faster models. That's not surprising, since these models are a hybrid of the best ideas from CNNs and transformers, so get the benefit of each. In fact, we see a similar thing even in the middle category of speeds -- the best is the ConvNeXt, which is a pure CNN, but which takes advantage of ideas from the transformers literature.\n",
    "\n",
    "For the slowest models, *beit* is the most accurate -- although we need to be a bit careful of interpreting this, since it's trained on a larger dataset (ImageNet-21k, which is also used for *vit* models).\n",
    "\n",
    "I'll add one other plot here, which is of speed vs parameter count. Often, parameter count is used in papers as a proxy for speed. However, as we see, there is a wide variation in speeds at each level of parameter count, so it's really not a useful proxy.\n",
    "\n",
    "(Parameter count may be be useful for identifying how much memory a model needs, but even for that it's not always a great proxy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7e85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:34:54.075784Z",
     "iopub.status.busy": "2025-05-29T14:34:54.075517Z",
     "iopub.status.idle": "2025-05-29T14:34:54.181229Z",
     "shell.execute_reply": "2025-05-29T14:34:54.179430Z",
     "shell.execute_reply.started": "2025-05-29T14:34:54.075754Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.scatter(df, width=w, height=h,\n",
    "    x='param_count_x',  y='secs', log_x=True, log_y=True, color='infer_img_size',\n",
    "    hover_name='model_org', hover_data=['infer_samples_per_sec', 'family']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5c9d8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55566693",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We'll now replicate the above analysis for training performance. First we grab the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c928b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:35:00.255327Z",
     "iopub.status.busy": "2025-05-29T14:35:00.254979Z",
     "iopub.status.idle": "2025-05-29T14:35:00.304594Z",
     "shell.execute_reply": "2025-05-29T14:35:00.303372Z",
     "shell.execute_reply.started": "2025-05-29T14:35:00.255259Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf = get_data('train', 'train_samples_per_sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43917cf8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now we can repeat the same *family* plot we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65391158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:35:00.689490Z",
     "iopub.status.busy": "2025-05-29T14:35:00.689144Z",
     "iopub.status.idle": "2025-05-29T14:35:00.710072Z",
     "shell.execute_reply": "2025-05-29T14:35:00.708815Z",
     "shell.execute_reply.started": "2025-05-29T14:35:00.689454Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_all(tdf, 'Training', 'train_img_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d199a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "...and we'll also look at our chosen subset of models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b60bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:35:02.381955Z",
     "iopub.status.busy": "2025-05-29T14:35:02.381691Z",
     "iopub.status.idle": "2025-05-29T14:35:02.402578Z",
     "shell.execute_reply": "2025-05-29T14:35:02.401413Z",
     "shell.execute_reply.started": "2025-05-29T14:35:02.381928Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_subs(tdf, 'Training', 'train_img_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771344a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Finally, we should remember that speed depends on hardware. If you're using something other than a modern NVIDIA GPU, your results may be different. In particular, I suspect that transformers-based models might have worse performance in general on CPUs (although I need to study this more to be sure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00611f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c421b854",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "存在问题无法正确显示图片"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30184,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.768488,
   "end_time": "2025-05-29T14:37:09.900457",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-29T14:35:47.131969",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
